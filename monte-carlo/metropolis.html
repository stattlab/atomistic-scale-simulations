
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>5.8. Metropolis Method &#8212; Atomistic Scale Simulations</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/image_dark_mode.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/myadmonitions.css?v=5b3d7684" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css?v=80cd6c28" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"d": ["{\\operatorname{d}\\!{#1}}", 1], "dd": ["{\\d{}^{#1} #2 \\over \\d{#3}^{#1}}", 3], "pp": ["{\\partial^{#1} #2 \\over \\partial #3^{#1}}", 3], "td": ["{\\left(\\pp{#1}{#2}{#3} \\right)_{#4}}", 4], "ubar": ["\\underline{#1}", 1], "vv": ["\\mathbf{#1}", 1]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'monte-carlo/metropolis';</script>
    <link rel="canonical" href="https://stattlab.github.io/atomistic-scale-simulations/monte-carlo/metropolis.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5.9. The Ising Model" href="ising-model.html" />
    <link rel="prev" title="5.7. Variance Reduction Techniques" href="variance-reduction.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Atomistic Scale Simulations</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../introduction/index.html">1. Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../introduction/why-atomistic-scale.html">1.1. Why are we interested in the atomistic scale?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introduction/what-are-simulations.html">1.2. What are Simulations?</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../molecular-models-and-interactions/index.html">2. Molecular Models and Interactions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../molecular-models-and-interactions/introduction.html">2.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../molecular-models-and-interactions/molecular-models.html">2.2. Molecular Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../molecular-models-and-interactions/periodic-boundary-conditions.html">2.3. Periodic Boundary Conditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../molecular-models-and-interactions/intramolecular-potentials.html">2.4. Intermolecular Potentials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../molecular-models-and-interactions/short-ranged-potentials.html">2.5. Short-Ranged Intramolecular Potentials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../molecular-models-and-interactions/electrostatics.html">2.6. Long-Range Potentials</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../statmech-thermo/index.html">3. Statistical Mechanics and Thermodynamics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../statmech-thermo/introduction.html">3.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../statmech-thermo/ensembles.html">3.2. Thermodyanmics and Ensembles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../statmech-thermo/statmech-ergodicity.html">3.3. Statistical Mechanics: Ensembles, Ergodicity and other Stuff</a></li>
<li class="toctree-l2"><a class="reference internal" href="../statmech-thermo/thermodynamic-properties.html">3.4. Thermodyanmics Properties</a></li>
<li class="toctree-l2"><a class="reference internal" href="../statmech-thermo/entropy-temperature.html">3.5. Entropy and Temperature</a></li>
<li class="toctree-l2"><a class="reference internal" href="../statmech-thermo/structural-correlations.html">3.6. Structural Correlations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../statmech-thermo/transport-coefficients.html">3.7. Transport Coefficients</a></li>
<li class="toctree-l2"><a class="reference internal" href="../statmech-thermo/statistical-errors.html">3.8. Statistical Errors</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../molecular-dynamics/index.html">4. Molecular Dynamics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../molecular-dynamics/introduction.html">4.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../molecular-dynamics/verlet-integration.html">4.2. Verlet Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../molecular-dynamics/thermostats.html">4.3. Thermostats</a></li>
<li class="toctree-l2"><a class="reference internal" href="../molecular-dynamics/langevin-dynamics.html">4.4. Langevin Dynamics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../molecular-dynamics/md-packages.html">4.5. Using MD Packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../molecular-dynamics/neighbor-list.html">4.6. Initialization and Neighbor Searching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../molecular-dynamics/high-performance-computing.html">4.7. HPC (High-Performance Computing)</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">5. Monte Carlo Simulations</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="introduction.html">5.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="random-numbers.html">5.2. Random Numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="monte-carlo-method.html">5.3. Monte Carlo Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="sampling.html">5.4. Sampling Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="phase-coexistence.html">5.5. Gibbs Ensemble and Phase Coexistence</a></li>
<li class="toctree-l2"><a class="reference internal" href="finite-size.html">5.6. Phase Transitions, Finite-size Scaling and Renormalization Group</a></li>
<li class="toctree-l2"><a class="reference internal" href="variance-reduction.html">5.7. Variance Reduction Techniques</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">5.8. Metropolis Method</a></li>
<li class="toctree-l2"><a class="reference internal" href="ising-model.html">5.9. The Ising Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="directed-mc.html">5.10. Directed Monte Carlo</a></li>
<li class="toctree-l2"><a class="reference internal" href="kinetic-mc.html">5.11. Kinetic Monte Carlo</a></li>
<li class="toctree-l2"><a class="reference internal" href="free-energy-from-sims.html">5.12. Free Energy Estimation in Simulations</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../references/references.html">6. References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../credits.html">7. Credits</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/stattlab/atomistic-scale-simulations" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/stattlab/atomistic-scale-simulations/issues/new?title=Issue%20on%20page%20%2Fmonte-carlo/metropolis.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/monte-carlo/metropolis.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Metropolis Method</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-metropolis-monte-carlo-method">5.8.1. The Metropolis Monte Carlo Method</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-measures-of-convergence">5.8.2. Practical Measures of Convergence</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#heat-bath-rules">5.8.3. Heat Bath Rules</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">5.8.4. References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="metropolis-method">
<h1><span class="section-number">5.8. </span>Metropolis Method<a class="headerlink" href="#metropolis-method" title="Link to this heading">#</a></h1>
<p>Now we come to a much more powerful Monte Carlo method. In statistical physics what is usually meant by Monte Carlo is not direct Monte Carlo sampling but <strong>random walks</strong>, or more specifically, <strong>Metropolis Monte Carlo</strong>. The random walk algorithm is one of the most important and pervasive numerical algorithm to be used on computers. The random walk or Metropolis algorithm was first used by Metropolis, Rosenbluth and Teller in 1953) though it is based on much earlier ideas of Markov. In statistics it is known as MCMC (Markov Chain Monte Carlo.) It is a general method of sampling arbitrary highly-dimensional probability distributions by taking a random walk through configuration space.</p>
<p>The problem with direct (or independent) sampling methods is that their efficiency goes to zero as the dimensionality of the space increases. Suppose we want to sample the probability distribution:</p>
<div class="math notranslate nohighlight">
\[
\pi(s)=\frac{\exp [-S(s)]}{Z},
\]</div>
<p>where <span class="math notranslate nohighlight">\(S(s)\)</span> is called the action or energy function and <span class="math notranslate nohighlight">\(s\)</span> is a variable in the space to be sampled. For classical systems <span class="math notranslate nohighlight">\(S(s)\)</span> would be equal to <span class="math notranslate nohighlight">\(\beta V(R)\)</span>, the classical Boltzmann distribution. The partition function <span class="math notranslate nohighlight">\(Z\)</span> normalizes the function <span class="math notranslate nohighlight">\(\pi\)</span> in its space and is usually not known. A direct sampling method would require sampling a function with a known normalization. Suppose we can directly sample a function <span class="math notranslate nohighlight">\(p_{m}(s) \approx \pi(s)\)</span>. One can show that the Monte Carlo variance of any quantity will depend on the ratio <span class="math notranslate nohighlight">\(\pi / p_{m}\)</span> as:</p>
<div class="math notranslate nohighlight">
\[
\text { variance } \propto \frac{&lt;\left(\pi / p_{m}\right)^{2}&gt;}{&lt;\pi / p_{m}&gt;^{2}}
\]</div>
<p>(averages taken with respect to <span class="math notranslate nohighlight">\(p_{m}\)</span>.) As the number of degrees of freedom in the system increases, the variance of the direct sampling approach will grow exponentially in the number of degrees of freedom. (Can you show this?)</p>
<p>In a random walk (Markov chain), one changes the state of the system randomly according to a fixed transition rule, <span class="math notranslate nohighlight">\(\mathcal{P}\left(s \rightarrow s^{\prime}\right)\)</span>, thus generating a random walk through state space, <span class="math notranslate nohighlight">\(\left\{s_{0}, s_{1}, s_{2} \ldots\right\}\)</span>. The definition of a Markov process is that the next step is chosen from a probability distribution that depends only on the “present” position. This makes it very easy to describe mathematically. The process is often called the drunkard’s walk. <span class="math notranslate nohighlight">\(\mathcal{P}\left(s \rightarrow s^{\prime}\right)\)</span> is a probability distribution so it satisfies</p>
<div class="math notranslate nohighlight">
\[
\sum_{s^{\prime}} \mathcal{P}\left(s \rightarrow s^{\prime}\right)=1
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
\mathcal{P}\left(s \rightarrow s^{\prime}\right) \geq 0 .
\]</div>
<p>Let <span class="math notranslate nohighlight">\(f_{n}(s)\)</span> be the probability distribution of the walker after <span class="math notranslate nohighlight">\(s\)</span> steps. Then it is easy to write the evolution of <span class="math notranslate nohighlight">\(f_{n}\)</span> in terms of <span class="math notranslate nohighlight">\(\mathcal{P}\)</span>.</p>
<div class="math notranslate nohighlight">
\[
f_{n+1}\left(s^{\prime}\right)=\sum_{s} f_{n}(s) \mathcal{P}\left(s \rightarrow s^{\prime}\right)
\]</div>
<p>or in vector-matrix notation:</p>
<div class="math notranslate nohighlight">
\[
f_{n+1}=\mathcal{P} f_{n}=\mathcal{P}^{n} f_{1}
\]</div>
<p>The first question is what is the final probability distribution (equilibrium state): <span class="math notranslate nohighlight">\(\lim _{n \rightarrow \infty} f_{n}\)</span> ? Any equilibrium state would be an eigenfunction of <span class="math notranslate nohighlight">\(\mathcal{P}\)</span> with unity eigenvalue. The next question is how many such eigenfunctions are there?</p>
<p>If the transition probability is ergodic, the distribution <span class="math notranslate nohighlight">\(f_{n}\)</span> will always converge to a unique equilibrium state. That means there is a unique solution to:</p>
<div class="math notranslate nohighlight">
\[
\sum_{s} f(s) \mathcal{P}\left(s \rightarrow s^{\prime}\right)=f\left(s^{\prime}\right)
\]</div>
<p>The transition is ergodic if:</p>
<ol class="arabic simple">
<li><p>One can move from any state to any other state in a finite number of steps with a nonzero probability, i.e., there are no barriers that restrict any walk to a subset of the full configuration space.</p></li>
<li><p>It is not periodic. An example of a periodic rule is if the hopping on a bipartite lattice always proceeds from the A sites to the B sites and vice-versa so that one never forgets which site one started on. Non-periodic rules hold if <span class="math notranslate nohighlight">\(\mathcal{P}(s \rightarrow s)&gt;0\)</span>; if there is always some chance of staying put.</p></li>
<li><p>The average return time to any state is finite. This is always true in a finite system (e.g. periodic boundary conditions). It would be violated in a model of the expanding universe where the system gets further and further from equilibrium because because there is no possibility of energy flowing between separated regions after the “big bang”.</p></li>
</ol>
<p>Under these conditions we can show that if <span class="math notranslate nohighlight">\(f_{n}(s)\)</span> is the probability distribution of random walks after <span class="math notranslate nohighlight">\(n\)</span> steps, with <span class="math notranslate nohighlight">\(f_{0}(s)\)</span> the initial condition, then:</p>
<div class="math notranslate nohighlight">
\[
f_{n}(s)=\pi+\sum_{\lambda} \epsilon_{\lambda}^{n} c_{\lambda} \phi_{\lambda}(s)
\]</div>
<p>where the <span class="math notranslate nohighlight">\(\epsilon_{\lambda}&lt;1\)</span>. Hence the probability distribution converges exponentially fast to the stationary distribution <span class="math notranslate nohighlight">\(\pi\)</span>. Furthermore, the convergence is monotonic (it does not oscillate). Specifically, what we mean is that the distance between <span class="math notranslate nohighlight">\(f_{n}\)</span> and <span class="math notranslate nohighlight">\(\pi\)</span> is strictly decreasing: <span class="math notranslate nohighlight">\(\left|f_{n}-\pi\right|&gt;\left|f_{n+1}-\pi\right|\)</span>.</p>
<p>The transition probabilities often satisfy the detailed balance property for same function: the transition rate from <span class="math notranslate nohighlight">\(s\)</span> to <span class="math notranslate nohighlight">\(s^{\prime}\)</span> equals the reverse rate,</p>
<div class="math notranslate nohighlight">
\[
\pi(s) \mathcal{P}\left(s \rightarrow s^{\prime}\right)=\pi\left(s^{\prime}\right) \mathcal{P}\left(s^{\prime} \rightarrow s\right)
\]</div>
<p>If the pair <span class="math notranslate nohighlight">\(\left\{\pi(s), \mathcal{P}\left(s \rightarrow s^{\prime}\right)\right\}\)</span> satisfy detailed balance and if <span class="math notranslate nohighlight">\(\mathcal{P}\left(s \rightarrow s^{\prime}\right)\)</span> is ergodic, then the random walk must eventually have <span class="math notranslate nohighlight">\(\pi\)</span> as its equilibrium distribution. To prove this fact, sum the previous equation over <span class="math notranslate nohighlight">\(s\)</span> and use Eq.(3) to simplify the right-hand-side. Detailed balance is one way of making sure that we sample <span class="math notranslate nohighlight">\(\pi\)</span>; it is a sufficient condition. Note that detailed balance is not necessary; common methods work directly with Eq. (7) as we will see.</p>
<section id="the-metropolis-monte-carlo-method">
<h2><span class="section-number">5.8.1. </span>The Metropolis Monte Carlo Method<a class="headerlink" href="#the-metropolis-monte-carlo-method" title="Link to this heading">#</a></h2>
<p>The Metropolis (rejection) method is a particular way of ensuring that the transition rules satisfy detailed balance. It does this by splitting the transition probability into an “a priori” sampling distribution <span class="math notranslate nohighlight">\(T\left(s \rightarrow s^{\prime}\right)\)</span> (a probability distribution that we can directly sample) and an acceptance probability <span class="math notranslate nohighlight">\(A\left(s \rightarrow s^{\prime}\right)\)</span> where <span class="math notranslate nohighlight">\(0 \leq A \leq 1\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\mathcal{P}\left(s \rightarrow s^{\prime}\right)=T\left(s \rightarrow s^{\prime}\right) A\left(s \rightarrow s^{\prime}\right)
\]</div>
<p>In the generalized Metropolis procedure, (Kalos and Whitlock, 1986), trial moves are accepted according to:</p>
<div class="math notranslate nohighlight">
\[
A\left(s \rightarrow s^{\prime}\right)=\min \left[1, q\left(s^{\prime} \rightarrow s\right)\right]
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
q\left(s \rightarrow s^{\prime}\right)=\frac{\pi\left(s^{\prime}\right) T\left(s^{\prime} \rightarrow s\right)}{\pi(s) T\left(s \rightarrow s^{\prime}\right)}
\]</div>
<p>It is easy to verify detailed balance and hence asymptotic convergence with this procedure by looking at the 3 cases:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(s=s^{\prime}\)</span> (trivial)</p></li>
<li><p><span class="math notranslate nohighlight">\(q\left(s \rightarrow s^{\prime}\right) \leq 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(q\left(s \rightarrow s^{\prime}\right) \geq 1\)</span></p></li>
</ul>
<p>You can avoid two common errors in Metropolis if you remember that: 1) if you can move from state <span class="math notranslate nohighlight">\(s\)</span> to <span class="math notranslate nohighlight">\(s^{\prime}\)</span> then the reverse move must also be possible ( <span class="math notranslate nohighlight">\(T\left(s \rightarrow s^{\prime}\right)\)</span> and <span class="math notranslate nohighlight">\(T\left(s^{\prime} \rightarrow s\right)\)</span> should be zero or non-zero together) and 2) moves that are not accepted are rejected and remain at the same location for at least one more step. Accepted or rejected steps contribute to averages in the same way.</p>
<p>Here is the generalized Metropolis algorithm:</p>
<ol class="arabic simple">
<li><p>Decide what distribution to sample ( <span class="math notranslate nohighlight">\(\pi(s)\)</span> ) and how to move from one state to another, <span class="math notranslate nohighlight">\(T\left(s \rightarrow s^{\prime}\right)\)</span></p></li>
<li><p>Initialize the state, pick <span class="math notranslate nohighlight">\(s_{0}\)</span>.</p></li>
<li><p>To advance the state from <span class="math notranslate nohighlight">\(s_{n}\)</span> to <span class="math notranslate nohighlight">\(s_{n+1}\)</span> :</p></li>
</ol>
<ul class="simple">
<li><p>Sample <span class="math notranslate nohighlight">\(s^{\prime}\)</span> from <span class="math notranslate nohighlight">\(T\left(s_{n} \rightarrow s^{\prime}\right)\)</span></p></li>
<li><p>Calculate the ratio:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
q=\frac{\pi\left(s^{\prime}\right) T\left(s^{\prime} \rightarrow s_{n}\right)}{\pi\left(s_{n}\right) T\left(s_{n} \rightarrow s^{\prime}\right)}
\]</div>
<ul class="simple">
<li><p>Accept or reject:</p></li>
</ul>
<p>If <span class="math notranslate nohighlight">\(q&gt;1\)</span> or if <span class="math notranslate nohighlight">\(q&gt;u_{n}\)</span> where <span class="math notranslate nohighlight">\(u_{n}\)</span> is a uniformly distributed r.n. in <span class="math notranslate nohighlight">\((0,1)\)</span> set <span class="math notranslate nohighlight">\(s_{n+1}=s^{\prime}\)</span>.
Otherwise set <span class="math notranslate nohighlight">\(s_{n+1}=s_{n}\)</span>
4. Throw away the first <span class="math notranslate nohighlight">\(\kappa\)</span> states as being out of equilibrium where <span class="math notranslate nohighlight">\(\kappa\)</span> is the “warm-up” time.
5. Collect averages every so often and block them to get error bars.</p>
<p>Here is a code for a generalized Metropolis:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>real*8 vold,vnew,sold(1:ndim),snew(1:ndim),pnew,pold
integer nsteps,istep,naccept,ndim
delta=?
call initstate(sold) !initialize the state
vold=action(sold)
naccept=0
do istep=1,nsteps
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>        call sample(sold,snew,pnew,1,delta,ndim) !sample snew, pnew is prob
        vnew = action(snew) !find the new action
        call sample(snew,sold,pold,0,delta,ndim) !find the prob of going backward
        a=exp(-vnew+vold)*pold/pnew !acceptance ratio
        if(a.gt.sprng()) then !accept the move
            sold=snew
            vold=vnew
            naccept=naccept+1
    endif
        call averages(sold)
    enddo
    write (*,*) &#39;acceptance ratio =&quot;,float(naccept)/float(nsteps)
    call pr_averages
    end
    subroutine sample(sold,snew,prob,ifnew,delta,ndim)
    integer ndim,ifnew,idim
    real*8 sold(1:ndim),snew(1:ndim),prob,delta
!classic Metropolis sampling in 1-D
    prob=1./delta
    if(ifnew.eq.1) then
        snew=sold
        idim=1+ndim*sprng() !pick particle at random
        snew(idim)=sold(idim)+(sprng()-.5)*delta !move it
        endif
    end
</pre></div>
</div>
<p>Consider the sampling of a classical Boltzmann distribution, <span class="math notranslate nohighlight">\(\exp (-\beta V(s))\)</span>. In the original Metropolis procedure, <span class="math notranslate nohighlight">\(T\left(s \rightarrow s^{\prime}\right)\)</span> was chosen to be a constant distribution inside a cube and zero outside. This is the classic rule: a single atom at a single time slice is displaced uniformly and the cube side <span class="math notranslate nohighlight">\(\Delta\)</span> is adjusted to achieve <span class="math notranslate nohighlight">\(50 \%\)</span> acceptance. Since <span class="math notranslate nohighlight">\(T\)</span> is a constant, it drops out of the acceptance formula. So the update rule is:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{r}^{\prime}=\mathbf{r}+\left(\mathbf{u}-\frac{1}{2}\right) \Delta
\]</div>
<p>with the acceptances based on <span class="math notranslate nohighlight">\(q=\exp \left(-\beta\left(V\left(s^{\prime}\right)-V(s)\right)\right.\)</span>. Moves that lower the potential energy are always accepted. Moves that raise the potential energy are often accepted if the energy cost (relative to <span class="math notranslate nohighlight">\(k_{B} T=1 / \beta\)</span> ) is small. Hence the random walk does not simply roll downhill. Thermal fluctuations can drive it uphill.</p>
<p>Some things to note about Metropolis:</p>
<ul class="simple">
<li><p>The acceptance ratio (number of successful moves/total number of trials) is a key quantity to keep track of and to quote. Clearly if the acceptance ratio is very small, one is doing a lot of work without moving through phase space. On the other hand, if the acceptance ratio is close to 1 , you could probably use larger steps and get faster convergence. There is a rule-of-thumb that it should be <span class="math notranslate nohighlight">\(1 / 2\)</span>, but in reality we have to look at the overall efficiency.
One nice feature is that particles can be moved one at a time. Note that <span class="math notranslate nohighlight">\(N\)</span> steps of Metropolis takes the same amount of time as 1 step of Molecular Dynamics. Consider what would happen if we moved <span class="math notranslate nohighlight">\(N\)</span> hard spheres all together. Let <span class="math notranslate nohighlight">\(p\)</span> be the probability of getting an overlap (and hence rejection) in the move of one hard sphere. Then the probability of getting an acceptance with <span class="math notranslate nohighlight">\(N\)</span> hard spheres is <span class="math notranslate nohighlight">\((1-p)^{N}=\exp (N \ln (1-p))\)</span> assuming no correlation. In order to get a reasonable acceptance <span class="math notranslate nohighlight">\(\delta\)</span> would have to be small enough so that <span class="math notranslate nohighlight">\(p \approx 1 / N\)</span> which would require extremely small steps.</p></li>
<li><p>Note that we need both the forward probability and the reverse probability if one has a nonuniform transition probability. Also note that we cannot calculate the normalization of <span class="math notranslate nohighlight">\(\pi\)</span> nor is it ever needed. Only ratios enter in.</p></li>
<li><p>One can show that the Metropolis acceptance formula is optimal among formulas of this kind which satisfy detailed balance. (The average acceptance ratio is as large as possible.)</p></li>
<li><p>In some systems, it is necessary to have several different kinds of moves, for example, moves that change path variables and other moves that change the permutation. So it is necessary to generalize the Metropolis procedure to the case in which one has a menu of possible moves. There are two ways of implementing such a menu. The simplest is to choose the type of move randomly, according to some fixed probability. For example, one can choose the particle to be updated from some distribution. One must include in the definition of <span class="math notranslate nohighlight">\(T\left(s \rightarrow s^{\prime}\right)\)</span> the probability of selecting that move from the menu (unless you can argue that it cancels out.) A more common procedure is to go through all possible atoms systematically. After one pass, moves of all coordinates have been attempted once. In this case, the transition probability does not satisfy detailed balance but it is easy to show that composition of moves will give a random walk with <span class="math notranslate nohighlight">\(\pi\)</span> as equilibrium distribution as long as each type of move individually satisfies detailed balance. Having many types of moves makes the algorithm much more robust, since before doing a calculation one does not necessarily know which moves will lead to rapid movement through phase space.</p></li>
</ul>
</section>
<section id="practical-measures-of-convergence">
<h2><span class="section-number">5.8.2. </span>Practical Measures of Convergence<a class="headerlink" href="#practical-measures-of-convergence" title="Link to this heading">#</a></h2>
<p>Since asymptotic convergence is easy to guarantee, the main issue is whether configuration space is explored thoroughly in a reasonable amount of computer time. Let us define a measure of the convergence rate and of the efficiency of a given Markov process. This is needed to compare the efficiency of different transition rules, to estimate how long the runs should be, and to calculate statistical errors. The rate of convergence is a function of the property being calculated. Generally one expects that there are local properties which converge quickly and other properties (such as order parameters near a phase boundary) which converge very slowly.</p>
<p>Let <span class="math notranslate nohighlight">\(\mathcal{O}(s)\)</span> be a given property and let its value at step <span class="math notranslate nohighlight">\(k\)</span> of the random walk be <span class="math notranslate nohighlight">\(\mathcal{O}_{k}\)</span>. Let the mean and intrinsic variance of <span class="math notranslate nohighlight">\(\mathcal{O}\)</span> be denoted by</p>
<div class="math notranslate nohighlight">
\[
\overline{\mathcal{O}}=\left\langle\mathcal{O}_{k}\right\rangle
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
\sigma_{\mathcal{O}}^{2}=\left\langle\left(\mathcal{O}_{k}-\overline{\mathcal{O}}\right)^{2}\right\rangle
\]</div>
<p>where the averages <span class="math notranslate nohighlight">\(\langle\ldots\rangle\)</span> are over <span class="math notranslate nohighlight">\(\pi\)</span>. These quantities depend only on the distribution <span class="math notranslate nohighlight">\(\pi\)</span>, not on the Monte Carlo procedure. We can show that the standard error of the estimate of the average, <span class="math notranslate nohighlight">\(\overline{\mathcal{O}}\)</span>, over a Markov chain with <span class="math notranslate nohighlight">\(P\)</span> steps, is</p>
<div class="math notranslate nohighlight">
\[
\operatorname{error}[\overline{\mathcal{O}}]=\sqrt{\frac{\kappa_{\mathcal{O}} \sigma_{\mathcal{O}}^{2}}{P}}
\]</div>
<p>The correlation time, <span class="math notranslate nohighlight">\(\kappa_{\mathcal{O}}\)</span>, defined as</p>
<div class="math notranslate nohighlight">
\[
\kappa_{\mathcal{O}}=1+2 \sum_{k=1}^{\infty} \frac{\left\langle\left(\mathcal{O}_{0}-\overline{\mathcal{O}}\right)\left(\mathcal{O}_{k}-\overline{\mathcal{O}}\right)\right\rangle}{\sigma_{\mathcal{O}}^{2}}
\]</div>
<p>gives the average number of steps to decorrelate the property <span class="math notranslate nohighlight">\(\mathcal{O}\)</span>. The correlation time will depend crucially on the transition rule and has a minimum value of 1 if one can move so far in configuration space that successive values are uncorrelated. In general, the number of independent steps which contribute to reducing the error bar from Eq. (17) is not <span class="math notranslate nohighlight">\(P\)</span> but <span class="math notranslate nohighlight">\(P / \kappa_{\mathcal{O}}\)</span>.</p>
<p>Hence to determine the true statistical error in a random walk, one needs to estimate the correlation time just as we had to do with MD simulations. To do this it is very important that the total length of the random walk be much greater than <span class="math notranslate nohighlight">\(\kappa_{\mathcal{O}}\)</span>. Otherwise the result and the error will be unreliable. Runs in which the number of steps is <span class="math notranslate nohighlight">\(P \gg \kappa_{\mathcal{O}}\)</span> are called well converged. In general, there is no mathematically rigorous procedure to determine <span class="math notranslate nohighlight">\(\kappa_{\mathcal{O}}\)</span>. Usually one must determine it from the random walk. It is a good practice occasionally to run very long runs to test that the results are well converged. Error bars can be conveniently determined by blocking the result over enough steps so that successive blocks are independently distributed.</p>
<p>The correlation time defined above is an equilibrium average. There is another correlation time relevant to Markov chains, namely, how many steps it takes to reach equilibrium from some starting state. Normally this will be at least as long as the equilibrium correlation time, but in some cases it can be much longer. The simplest way of testing convergence is to start the random walk from several, radically different, starting places and see if a variety of well-chosen properties converge to the same values. A starting place appropriate for a dense liquid or solid is with all the atoms sitting on lattice sites. However, it may take a very large number of steps for the initial solid to melt. Meta-stability and hysteresis are characteristic near a (first-order) phase boundary. A random starting place is with placing each variable randomly in the total space. It may be very difficult for the system to go to the equilibrium distribution from this starting place. More physical starting places are well-converged states at neighboring densities and temperatures.</p>
<p>The efficiency of a random-walk procedure (for the property <span class="math notranslate nohighlight">\(\mathcal{O}\)</span> ) is defined as how quickly the errors bars decrease as a function of computer time,</p>
<div class="math notranslate nohighlight">
\[
\xi_{\mathcal{O}}=\frac{1}{\kappa_{\mathcal{O}} \sigma_{\mathcal{O}}^{2} T}
\]</div>
<p>where <span class="math notranslate nohighlight">\(T\)</span> is the computer time per step. Hence the efficiency is independent of the length of the calculation and is the figure-of-merit for a given algorithm. The efficiency depends not only on the algorithm but also on the computer and the implementation. Methods that generate more steps per hour are, other things being equal, more efficient. We are fortunate to live in a time when the efficiency is increasing because of rapid advances in computers. Improvements in algorithms can also give rise to dramatic increases in efficiency. If we ignore how much computer time a move takes, an optimal transition rule is one which minimizes <span class="math notranslate nohighlight">\(\kappa_{\mathcal{O}}\)</span>, since <span class="math notranslate nohighlight">\(\sigma_{\mathcal{O}}^{2}\)</span> is independent of the sampling algorithm.</p>
<p>There are advantages in defining an intrinsic efficiency of an algorithm since one does not necessarily want to determine the efficiency for each property separately. It is best to optimize an algorithm to compute a whole spectrum of properties. Diffusion of paths through phase space provides at least a intuitive measure of convergence. Let us define the diffusion constant <span class="math notranslate nohighlight">\(D_{R}\)</span> of an algorithm by</p>
<div class="math notranslate nohighlight">
\[
D_{R}=\left\langle\frac{\left[\left(R_{n+1}-R_{n}\right)\right]^{2}}{T}\right\rangle
\]</div>
<p>where <span class="math notranslate nohighlight">\(R_{n+1}-R_{n}\)</span> is the total change in one Monte Carlo step and <span class="math notranslate nohighlight">\(T\)</span> is the CPU time per step. Note that this change is zero if a move is rejected. For the “classic” Metropolis procedure we see that the diffusion constant is roughly:</p>
<div class="math notranslate nohighlight">
\[
D_{R} \propto\langle A\rangle \Delta^{2}
\]</div>
<p>Hence one wants to increase <span class="math notranslate nohighlight">\(\Delta\)</span> until the acceptance ratio starts decreasing too rapidly. This leads to an optimal choice for <span class="math notranslate nohighlight">\(\Delta\)</span>. The values of these diffusion constants depend not only on the computer and the algorithm, but also on the physics. Diffusion of the atoms in a solid is much less than in a liquid, irrespective of the algorithm.</p>
</section>
<section id="heat-bath-rules">
<h2><span class="section-number">5.8.3. </span>Heat Bath Rules<a class="headerlink" href="#heat-bath-rules" title="Link to this heading">#</a></h2>
<p>Usually transition rules are local; at a given step only a few coordinates are moved. If we try to move too many variables simultaneously, the move will almost certainly be rejected, leading to long correlation times. Given a transition rule, we define the neighborhood, <span class="math notranslate nohighlight">\(\mathcal{N}(s)\)</span>, for each point in state space as the set of states <span class="math notranslate nohighlight">\(s^{\prime}\)</span> that can be reached in a single move from <span class="math notranslate nohighlight">\(s\)</span>. (It is essential for detailed balance that the neighborhoods be reflexive. If <span class="math notranslate nohighlight">\(s^{\prime}\)</span> is in the neighborhood of <span class="math notranslate nohighlight">\(s\)</span>, then <span class="math notranslate nohighlight">\(s\)</span> is in the neighborhood of <span class="math notranslate nohighlight">\(s^{\prime}\)</span>.) With the heat-bath transition rule, one samples elements from the neighborhood with a transition probability proportional to their equilibrium distribution,</p>
<div class="math notranslate nohighlight">
\[
T_{H B}\left(s \rightarrow s^{\prime}\right)=\frac{\pi_{s^{\prime}}}{C_{s}}
\]</div>
<p>where the normalization constant is</p>
<div class="math notranslate nohighlight">
\[
C_{s}=\sum_{s^{\prime \prime} \in \mathcal{N}(s)} \pi_{s^{\prime \prime}}
\]</div>
<p>Then one sees, by substitution into the acceptance probability formula, that the acceptance probability will be</p>
<div class="math notranslate nohighlight">
\[
A\left(s \rightarrow s^{\prime}\right)=\min \left[1, \frac{C_{s}}{C_{s^{\prime}}}\right]
\]</div>
<p>If the neighborhood of <span class="math notranslate nohighlight">\(s\)</span> equals the neighborhood of <span class="math notranslate nohighlight">\(s^{\prime}\)</span> then all moves will be accepted. For all transition rules with the same neighborhoods, the heat-bath rule will converge to the equilibrium distribution fastest and have the smallest correlation time. Within the neighborhood, with heat bath one comes into equilibrium within a single step.</p>
<p>This heat-bath rule is frequently used in lattice spin models where one can easily compute the normalization constant, <span class="math notranslate nohighlight">\(C_{s}\)</span> needed in the acceptance ratio formula and to perform the sampling. The heat-bath approach is not often used in continuum systems because the normalizations are difficult to compute; note that the integral in Eq. (23) extends over all space. In Monte Carlo on a classical system, the new atom could be anywhere in the box. One has to compute a one-particle partition function at each step. A repulsive potential will cut holes in the uniform distribution where another atom is present. Although it would be possible to develop sophisticated ways of sampling <span class="math notranslate nohighlight">\(T_{H B}\)</span>, it has been found more efficient to further approximate <span class="math notranslate nohighlight">\(T_{H B}\)</span> by some function that can be sampled quickly and let the Metropolis algorithm correct the sampling, since all that matters in the end is the efficiency. For continuum systems the idea is to find a method close to the heat-bath rule, so that the correlation time is small, but with a transition rule which is able to be executed quickly.</p>
</section>
<section id="references">
<h2><span class="section-number">5.8.4. </span>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Metropolis, N., A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, and E. Teller, 1953, J. Chem. Phys. 21, 1087.</p></li>
<li><p>Allen, M. P., and D. J. Tildesley, 1987, Computer Simulation of Liquids (Oxford University, New York). pgs. 114-123.</p></li>
<li><p>Kalos, M. H., and P. A. Whitlock, 1986, Monte Carlo Methods Volume I: Basics (Wiley, New York). pgs. 73-86.
Hammersley, J. M., and D. C. Handscomb, 1964, Monte Carlo Methods (Chapman and Hall, London). pgs. 113-122.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./monte-carlo"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="variance-reduction.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">5.7. </span>Variance Reduction Techniques</p>
      </div>
    </a>
    <a class="right-next"
       href="ising-model.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5.9. </span>The Ising Model</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-metropolis-monte-carlo-method">5.8.1. The Metropolis Monte Carlo Method</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-measures-of-convergence">5.8.2. Practical Measures of Convergence</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#heat-bath-rules">5.8.3. Heat Bath Rules</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">5.8.4. References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Antonia Statt
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>